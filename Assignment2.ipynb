{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This assignment may be worked individually or in pairs. \n",
    "## Enter your name/names here:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names here\n",
    "#Abhishek Dayal\n",
    "#Nathan Daniel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assignment 2: Naive Bayes and KNN classifier\n",
    "\n",
    "In this assignment you'll implement the Naive Bayes and KNN classifiers to classify patients as either having or not having diabetic retinopathy. For this task we'll be using the same Diabetic Retinopathy data set which was used in the previous assignment on decision trees. The implementation details are up to you but, generally it is a good idea to divide your code up into helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Headers\n",
    "# You are welcome to add additional headers if you wish\n",
    "# EXCEPT for scikit-learn... You may NOT use scikit-learn for this assignment!\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import log\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from a CSV file. You may choose to store it any any format you wish, like a Pandas dataframe, or any other data structure you'd like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    data = []\n",
    "#     your code goes here\n",
    "    data = pd.read_csv(filename, header=None)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Naive Bayes Classifier\n",
    "\n",
    "Naive Bayes (NB) classifier is a simple probabilistic classifier that is based on applying the Bayes' theorem and assumes a strong (naive) independence between features. The Diabetic Retinopathy data set contains both categorical and continuous features. Dealing with categorical features has been discussed in detail in class. Continuous attributes, on the other hand, are more interesting to handle. Most commonly, this is done by assuming normal probability distribution over the feature values or by binning the attribute values in a fixed number of bins. In this assignment you'll be implementing the binning approach. For each continuous attribute, you'll construct 3 equal sized bins. For example, feature 5 ranges from `[1 - 120]` the 3 bins that you'll construct will be `[1 - 40]`, `[41 - 80]`, `[81 - 120]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Implement a Naive Bayes classifier. Measure the accuracy of your classifier using 5-fold cross validation and display the confusion matrix. Also print the precision and recall for class label 1 (patients that have been diagnosed with the disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREP\n",
    "# bin continuous attributes (needs to be done with subset of df that is training data)\n",
    "def bin_df(df):\n",
    "    bins_dict = dict()\n",
    "    for c in range(2,18):\n",
    "        out, bins = pd.cut(df[c], 3, retbins=True, labels=[1,2,3])\n",
    "    #    bins = list(cut[1])\n",
    "        bins_dict[c] = list(bins)\n",
    "    #    out = cut[0]\n",
    "        df[c] = out\n",
    "\n",
    "    df.head()\n",
    "    return (df, bins_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(df, record):\n",
    "    #CLASSIFY\n",
    "    # maybe use groupBy?\n",
    "    # calculate ~probability of 1\n",
    "        # P(record[0]| class=1) * ... * P(record[18]| class=1) * P(class=1)\n",
    "    prob1 = df[df[19] == 1].count()[0]/df.shape[0]\n",
    "    prob0 = df[df[19] == 0].count()[0]/df.shape[0]\n",
    "#     print(prob1)\n",
    "    groups = df.groupby(df[19])\n",
    "    g1 = groups.get_group(1)\n",
    "    g0 = groups.get_group(0)\n",
    "    \n",
    "    print('RECORD\\n', record)\n",
    "    print('G1\\n', g1.head())\n",
    "    for i in range(0,18):\n",
    "        rval = record[0][i]\n",
    "        print(\"rval\", rval)\n",
    "        print(\"numerator\", g1[g1[i] == rval].count()[0])\n",
    "        print(\"g1 size\", g1.shape[0])\n",
    "        prob1 *= g1[g1[i] == rval].count()[0] / g1.shape[0]\n",
    "    # calculate ~probability of 0\n",
    "        # P(record[0]| class=0) * ... * P(record[18]| class=0) * P(class=0)\n",
    "    for i in range(0,18):\n",
    "        rval = record[0][i]\n",
    "        prob0 *= g0[g0[i] == rval].count()[0] / g0.shape[0]\n",
    "    # return greater of ~probabilities\n",
    "    \n",
    "    return 1 if prob1 > prob0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RECORD\n",
      " <pandas.core.indexing._LocIndexer object at 0x00000288699DC278>\n",
      "G1\n",
      "      0   1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17  18  19\n",
      "232   1   1  2  2  2  2  1  1  2  1  1  1  1  1  1  1  2  2   1   1\n",
      "234   1   1  2  2  2  3  3  2  1  1  1  1  1  1  2  3  2  2   0   1\n",
      "236   1   0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  1   1   1\n",
      "237   1   0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  2   0   1\n",
      "238   1   0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  2   1   1\n",
      "rval 1\n",
      "numerator 483\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 431\n",
      "g1 size 483\n",
      "rval 2\n",
      "numerator 176\n",
      "g1 size 483\n",
      "rval 2\n",
      "numerator 198\n",
      "g1 size 483\n",
      "rval 2\n",
      "numerator 203\n",
      "g1 size 483\n",
      "rval 2\n",
      "numerator 187\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 287\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 340\n",
      "g1 size 483\n",
      "rval 2\n",
      "numerator 81\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 433\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 455\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 478\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 479\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 479\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 476\n",
      "g1 size 483\n",
      "rval 1\n",
      "numerator 473\n",
      "g1 size 483\n",
      "rval 2\n",
      "numerator 195\n",
      "g1 size 483\n",
      "rval 2\n",
      "numerator 160\n",
      "g1 size 483\n",
      "1\n",
      "RECORD\n",
      " <pandas.core.indexing._LocIndexer object at 0x0000028869A00188>\n",
      "G1\n",
      "    0   1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17  18  19\n",
      "2   1   1  2  2  2  2  2  2  1  1  1  1  1  1  1  1  3  2   0   1\n",
      "4   1   1  1  1  2  2  2  2  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "5   1   1  1  1  2  2  2  2  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "6   1   0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  2   0   1\n",
      "8   1   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "rval 1\n",
      "numerator 488\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 438\n",
      "g1 size 488\n",
      "rval 2\n",
      "numerator 185\n",
      "g1 size 488\n",
      "rval 2\n",
      "numerator 198\n",
      "g1 size 488\n",
      "rval 2\n",
      "numerator 201\n",
      "g1 size 488\n",
      "rval 2\n",
      "numerator 180\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 254\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 302\n",
      "g1 size 488\n",
      "rval 2\n",
      "numerator 79\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 447\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 463\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 482\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 485\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 482\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 479\n",
      "g1 size 488\n",
      "rval 1\n",
      "numerator 480\n",
      "g1 size 488\n",
      "rval 2\n",
      "numerator 198\n",
      "g1 size 488\n",
      "rval 2\n",
      "numerator 173\n",
      "g1 size 488\n",
      "1\n",
      "RECORD\n",
      " <pandas.core.indexing._LocIndexer object at 0x0000028869B4EAE8>\n",
      "G1\n",
      "    0   1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17  18  19\n",
      "2   1   1  2  2  2  2  2  2  1  1  1  1  1  1  1  1  3  2   0   1\n",
      "4   1   1  1  1  2  2  2  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "5   1   1  1  1  2  2  2  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "6   1   0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  2   0   1\n",
      "8   1   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "rval 1\n",
      "numerator 491\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 444\n",
      "g1 size 491\n",
      "rval 2\n",
      "numerator 182\n",
      "g1 size 491\n",
      "rval 2\n",
      "numerator 209\n",
      "g1 size 491\n",
      "rval 2\n",
      "numerator 219\n",
      "g1 size 491\n",
      "rval 2\n",
      "numerator 202\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 272\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 331\n",
      "g1 size 491\n",
      "rval 2\n",
      "numerator 81\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 450\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 456\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 484\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 487\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 485\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 481\n",
      "g1 size 491\n",
      "rval 1\n",
      "numerator 484\n",
      "g1 size 491\n",
      "rval 2\n",
      "numerator 201\n",
      "g1 size 491\n",
      "rval 2\n",
      "numerator 268\n",
      "g1 size 491\n",
      "1\n",
      "RECORD\n",
      " <pandas.core.indexing._LocIndexer object at 0x0000028869ABD5E8>\n",
      "G1\n",
      "    0   1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17  18  19\n",
      "2   1   1  2  2  2  2  2  2  1  1  1  1  1  1  1  1  3  2   0   1\n",
      "4   1   1  1  1  2  2  2  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "5   1   1  1  1  2  2  2  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "6   1   0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  2   0   1\n",
      "8   1   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "rval 1\n",
      "numerator 487\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 439\n",
      "g1 size 487\n",
      "rval 2\n",
      "numerator 187\n",
      "g1 size 487\n",
      "rval 2\n",
      "numerator 212\n",
      "g1 size 487\n",
      "rval 2\n",
      "numerator 218\n",
      "g1 size 487\n",
      "rval 2\n",
      "numerator 203\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 265\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 326\n",
      "g1 size 487\n",
      "rval 2\n",
      "numerator 91\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 449\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 463\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 480\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 483\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 481\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 477\n",
      "g1 size 487\n",
      "rval 1\n",
      "numerator 478\n",
      "g1 size 487\n",
      "rval 2\n",
      "numerator 204\n",
      "g1 size 487\n",
      "rval 2\n",
      "numerator 190\n",
      "g1 size 487\n",
      "1\n",
      "RECORD\n",
      " <pandas.core.indexing._LocIndexer object at 0x0000028869AA87C8>\n",
      "G1\n",
      "    0   1  2  3  4  5  6  7  8  9  10 11 12 13 14 15 16 17  18  19\n",
      "2   1   1  2  2  2  2  2  2  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "4   1   1  1  1  2  2  2  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "5   1   1  1  1  2  2  2  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "6   1   0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  3  2   0   1\n",
      "8   1   1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  2  2   0   1\n",
      "rval 1\n",
      "numerator 495\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 444\n",
      "g1 size 495\n",
      "rval 2\n",
      "numerator 179\n",
      "g1 size 495\n",
      "rval 2\n",
      "numerator 201\n",
      "g1 size 495\n",
      "rval 2\n",
      "numerator 212\n",
      "g1 size 495\n",
      "rval 2\n",
      "numerator 199\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 280\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 342\n",
      "g1 size 495\n",
      "rval 2\n",
      "numerator 79\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 456\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 472\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 484\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 486\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 487\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 488\n",
      "g1 size 495\n",
      "rval 1\n",
      "numerator 490\n",
      "g1 size 495\n",
      "rval 2\n",
      "numerator 296\n",
      "g1 size 495\n",
      "rval 2\n",
      "numerator 186\n",
      "g1 size 495\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "# column 19 is class label\n",
    "\n",
    "# columns 2 - 17\n",
    "# Col 2: min - 1 max 130\n",
    "# Col 3: min - 1 max 132\n",
    "# Col 4: min - 1 max 120\n",
    "# Col 5: min - 1 max 105\n",
    "# Col 6: min - 1 max 97\n",
    "# Col 7: min - 1 max 89\n",
    "# Col 8: min - 0.349274 max 403.93910800000003\n",
    "# Col 9: min - 0.0 max 167.131427\n",
    "# Col 10: min - 0.0 max 106.07009199999999\n",
    "# Col 11: min - 0.0 max 59.766121\n",
    "# Col 12: min - 0.0 max 51.423208\n",
    "# Col 13: min - 0.0 max 20.098605\n",
    "# Col 14: min - 0.0 max 5.937799\n",
    "# Col 15: min - 0.0 max 3.086753\n",
    "# Col 16: min - 0.367762 max 0.592217\n",
    "# Col 17: min - 0.05790599999999999 max 0.21919899999999998\n",
    "# your code goes here\n",
    "\n",
    "df = get_data('messidor_features.txt')\n",
    "\n",
    "# TODO: trim off class label and hold separately\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#OUTPUT\n",
    "# 5-fold cross validation\n",
    "\n",
    "data_len = df.shape[0]\n",
    "interval = (int)(data_len / 5)\n",
    "\n",
    "# print(data_len)\n",
    "# print(interval)\n",
    "\n",
    "\n",
    "for i in range(0, data_len - interval, interval):\n",
    "\n",
    "    # partition data into train_set and test_set\n",
    "    train_set = df[0:i].append(df[i+interval:])\n",
    "    test_set = df[i:i+interval]\n",
    "    \n",
    "    #print(test_set.head())\n",
    "    \n",
    "    # get binned df (tuple)\n",
    "    binned_train_set, bins = bin_df(train_set)\n",
    "    \n",
    "    #print(binned_train_set.head())\n",
    "    tester_record = pd.DataFrame([[1,   1,  2,  2,  2,  2,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1],\n",
    "                                 [3,   1,  2,  2,  2,  2,  1,  1,  2,  1,  1,  1,  1,  1,  1,  1,  2,  2,  1,  1]])\n",
    "    print(classify(binned_train_set, tester_record.loc(0)))\n",
    "    # run testing set\n",
    "    #for record in test_set:\n",
    "    #    classify(binned_train_set, record)\n",
    "    # print and factor in new accuracy (store numbers for misplaced testing figures for confusion matrix)\n",
    "\n",
    "# output confusion matrix\n",
    "\n",
    "# print precision/recall\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: K Nearest Neighbor (KNN) Classifier\n",
    "\n",
    "The KNN classifier consists of two stages:-\n",
    "- In the training stage, the classifier takes the training data and simply memorizes it\n",
    "- In the test stage, the classifier compares the test data with the training data and simply returns the maximum occuring label of the k nearest data points.\n",
    "\n",
    "The distance calculation method is central to the algorithm, typically Euclidean distance is used but other distance metrics like Manhattan distance can also be used. In this assignment you'll be implementing the classifier using the Euclidean distance metric. It is important to note that Euclidean distance is very sensitive to the scaling of different attributes hence, before you can build your classifier you have to normalize the values of each feature in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. Normalize the dataset so that each feature value lies between `[0-1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3. Build your KNN classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Find the best value of k for this data. Try k ranging from 1 to 10. For each k value, use a 5-fold cross validation to evaluate the accuracy with that k. In each fold of CV, divide your data into a training set and a validation set. Print out the best value of k and the accuracy achieved with that value. Return the best value of k. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Now measure the accuracy of your classifier using 5-fold cross validation. In each fold of this CV, divide your data into a training set and a test set. The training set should get sent through your code for Q4, resulting in a value of k to use. Using that k, calculate an accuracy on the test set. You will average the accuracy over all 5 folds to obtain the final accuracy measurement. Print the accuracy as well as the precision and recall for class label 1 (patients that have been diagnosed with the disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
